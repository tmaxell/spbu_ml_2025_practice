{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d5bbb5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "57896730",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "store = pd.read_csv(\"data/steam_store_data_2024.csv\")\n",
    "spy = pd.read_csv(\"data/output_steamspy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f0255d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# тут попробуем обработать spy датасетик\n",
    "def parse_owners(owners_range):\n",
    "    try:\n",
    "        low, high = owners_range.replace(\",\", \"\").split(\" .. \")\n",
    "        return (int(low) + int(high)) // 2\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "spy[\"owners_est\"] = spy[\"owners\"].apply(parse_owners)\n",
    "\n",
    "spy.rename(columns={\"appid\": \"app_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "52f369e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# аналогично для стора\n",
    "def parse_price(price_str):\n",
    "    try:\n",
    "        return float(price_str.replace(\"$\", \"\"))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def parse_discount(sale_str):\n",
    "    try:\n",
    "        return int(sale_str.replace(\"-\", \"\").replace(\"%\", \"\"))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "store[\"price_num\"] = store[\"price\"].apply(parse_price)\n",
    "store[\"sale_pct\"] = store[\"salePercentage\"].apply(parse_discount)\n",
    "\n",
    "# закодируем LabelEncoder\n",
    "for col in [\"recentReviews\", \"allReviews\"]:\n",
    "    store[col] = store[col].astype(str)\n",
    "    le = LabelEncoder()\n",
    "    store[col + \"_enc\"] = le.fit_transform(store[col])\n",
    "\n",
    "# переименуем для join\n",
    "store.rename(columns={\"title\": \"name\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0f1637a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data = pd.merge(spy, store, on=\"name\", how=\"inner\")\n",
    "game_data_small = game_data[[\"app_id\", \"owners_est\", \"price_num\", \"sale_pct\", \"recentReviews_enc\", \"allReviews_enc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d8f38f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.merge(train, game_data_small, on=\"app_id\", how=\"left\")\n",
    "test_full = pd.merge(test, game_data_small, on=\"app_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b7d6745b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tmaxell/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# обработаем текст\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words and len(word) > 2]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "train_full[\"clean_content\"] = train_full[\"content\"].apply(clean_text)\n",
    "test_full[\"clean_content\"] = test_full[\"content\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad09d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_text_train = tfidf.fit_transform(train_full[\"clean_content\"])\n",
    "X_text_test = tfidf.transform(test_full[\"clean_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c7316",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\"owners_est\", \"price_num\", \"sale_pct\", \"recentReviews_enc\", \"allReviews_enc\"]\n",
    "X_numeric_train = train_full[numeric_cols].fillna(0)\n",
    "X_numeric_test = test_full[numeric_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b15933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = hstack([X_text_train, X_numeric_train])\n",
    "X_test = hstack([X_text_test, X_numeric_test])\n",
    "y_train = train_full[\"is_positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35057b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores по фолдам: [0.83583977 0.83534673 0.83696554 0.84028633 0.83195866]\n",
      "Средний F1: 0.83607940413081\n",
      "Файл submission.csv сохранён.\n"
     ]
    }
   ],
   "source": [
    "X_train = csr_matrix(X_train)\n",
    "X_test = csr_matrix(X_test)\n",
    "\n",
    "# Целевая переменная\n",
    "y = y_train.values\n",
    "\n",
    "# Модель\n",
    "lr = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "\n",
    "# Кросс-валидация Stratified по F1\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scores = cross_val_score(lr, X_train, y, cv=cv, scoring='f1')\n",
    "\n",
    "print(\"F1 scores по фолдам:\", f1_scores)\n",
    "print(\"Средний F1:\", np.mean(f1_scores))\n",
    "\n",
    "# Обучаем модель на всех данных\n",
    "lr.fit(X_train, y)\n",
    "\n",
    "# Предсказание на тесте\n",
    "test_preds = lr.predict(X_test)\n",
    "\n",
    "# Формируем submission\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test_full[\"id\"],\n",
    "    \"sentiment\": test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Файл submission.csv сохранён.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbca32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punct(text):\n",
    "    return sum([1 for c in text if c in \".,;:!?\"])\n",
    "\n",
    "def count_upper(text):\n",
    "    if len(text) == 0:\n",
    "        return 0\n",
    "    return sum(1 for c in text if c.isupper()) / len(text)\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "for df in [train_full, test_full]:\n",
    "    df[\"text_len\"] = df[\"content\"].fillna(\"\").apply(len)\n",
    "    df[\"word_count\"] = df[\"content\"].fillna(\"\").apply(count_words)\n",
    "    df[\"punct_count\"] = df[\"content\"].fillna(\"\").apply(count_punct)\n",
    "    df[\"upper_ratio\"] = df[\"content\"].fillna(\"\").apply(count_upper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    \"owners_est\", \"price_num\", \"sale_pct\",\n",
    "    \"recentReviews_enc\", \"allReviews_enc\",\n",
    "    \"text_len\", \"word_count\", \"punct_count\", \"upper_ratio\"\n",
    "]\n",
    "\n",
    "X_numeric_train = train_full[numeric_cols].fillna(0)\n",
    "X_numeric_test = test_full[numeric_cols].fillna(0)\n",
    "\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "X_train = hstack([X_text_train, csr_matrix(X_numeric_train.values)])\n",
    "X_test = hstack([X_text_test, csr_matrix(X_numeric_test.values)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3910ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Преобразуем в формат для XGB и LGB (лучше не использовать sparse)\n",
    "X_train_dense = X_train.todense()\n",
    "X_test_dense = X_test.todense()\n",
    "\n",
    "y = train_full[\"is_positive\"].values\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_params = {\n",
    "    'max_depth': [3, 5],\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb_model, xgb_params, scoring='f1', cv=3, verbose=1)\n",
    "xgb_grid.fit(X_train_dense, y)\n",
    "\n",
    "print(\"Лучшие параметры XGB:\", xgb_grid.best_params_)\n",
    "print(\"Лучший F1 XGB:\", xgb_grid.best_score_)\n",
    "\n",
    "# LightGBM\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "lgb_params = {\n",
    "    'max_depth': [3, 5],\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1]\n",
    "}\n",
    "\n",
    "lgb_grid = GridSearchCV(lgb_model, lgb_params, scoring='f1', cv=3, verbose=1)\n",
    "lgb_grid.fit(X_train_dense, y)\n",
    "\n",
    "print(\"Лучшие параметры LGB:\", lgb_grid.best_params_)\n",
    "print(\"Лучший F1 LGB:\", lgb_grid.best_score_)\n",
    "\n",
    "# Выбираем лучшую модель\n",
    "best_model = xgb_grid.best_estimator_ if xgb_grid.best_score_ > lgb_grid.best_score_ else lgb_grid.best_estimator_\n",
    "\n",
    "# Обучаем на всех данных\n",
    "best_model.fit(X_train_dense, y)\n",
    "\n",
    "# Предсказание\n",
    "test_preds = best_model.predict(X_test_dense)\n",
    "\n",
    "# Сохраняем submission\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test_full[\"id\"],\n",
    "    \"sentiment\": test_preds\n",
    "})\n",
    "submission.to_csv(\"submission_advanced.csv\", index=False)\n",
    "print(\"submission_advanced.csv сохранён.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60220e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "calibrated_clf = CalibratedClassifierCV(best_model, cv='prefit', method='isotonic')\n",
    "calibrated_clf.fit(X_train_dense, y)\n",
    "\n",
    "# Калиброванное предсказание вероятностей\n",
    "test_probs = calibrated_clf.predict_proba(X_test_dense)[:,1]\n",
    "\n",
    "# Перекодируем в классы по порогу 0.5\n",
    "test_preds_calibrated = (test_probs > 0.5).astype(int)\n",
    "\n",
    "# Сохраняем калиброванный сабмишн\n",
    "submission_calibrated = pd.DataFrame({\n",
    "    \"id\": test_full[\"id\"],\n",
    "    \"sentiment\": test_preds_calibrated\n",
    "})\n",
    "submission_calibrated.to_csv(\"submission_calibrated.csv\", index=False)\n",
    "print(\"submission_calibrated.csv сохранён.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67da0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# SHAP для XGBoost/LightGBM\n",
    "explainer = shap.Explainer(best_model, X_train_dense)\n",
    "shap_values = explainer(X_train_dense)\n",
    "\n",
    "# Визуализация важности признаков\n",
    "shap.summary_plot(shap_values, features=X_train_dense, feature_names=list(tfidf.get_feature_names_out()) + numeric_cols)\n",
    "\n",
    "# Permutation Importance\n",
    "result = permutation_importance(best_model, X_train_dense, y, scoring='f1', n_repeats=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "sorted_idx = result.importances_mean.argsort()[::-1]\n",
    "feature_names = list(tfidf.get_feature_names_out()) + numeric_cols\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(range(20), result.importances_mean[sorted_idx][:20], align='center')\n",
    "plt.yticks(range(20), np.array(feature_names)[sorted_idx][:20])\n",
    "plt.xlabel(\"Permutation Importance (mean)\")\n",
    "plt.title(\"Top 20 важнейших признаков\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
